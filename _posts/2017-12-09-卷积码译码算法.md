---
layout: post
title: Viterbi算法和BCJR算法
date: 2017-12-09
description: 译码算法
tag: 译码算法
---

# Viterbi算法和BCJR算法


Viterbi算法是最大似然译码（ML）因此码字的误码率是被最小化的，而BCJR算法属于最大后验概率译码其信息位误码率被最小化。

## 最大似然译码

[ML](https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1 "https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1")

### 似然函数

[似然函数](https://zh.wikipedia.org/wiki/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0 "https://zh.wikipedia.org/wiki/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0")
<br />
**概率**用于在已知一些参数的情况下，预测接下来的观测所得到的结果，而**似然性**则是用于在已知某些观测所得到的结果时，对有关事物的性质的参数进行估计。
<br />
因此基于这种意义，似然函数可以理解为条件概率的逆反运算。
<br />
例如在已知参数B时，事件A发生的概率表示为:
<br />
<center>
$P(A|B) = \frac{{P(A,B)}}{{P(B)}}$(1.1)	
</center>
通过贝叶斯定理，
$$P(B|A) = \frac{{P(A,B)P(B)}}{{P(A)}}　　(1.2)$$
如果A,B表示两个事件则公式(1.1)表示在事件B发生的条件下发生事件A的概率，而公式(1.2)则表示在事件A发生的条件下发生事件B的概率。也可以反过来构造表示似然性，在已知事件A发生的条件下，运用似然函数
$L(B|A)$，估计参数B的可能性。在形式上而言，似然函数也是一种条件概率函数，只不过所关注的变量改变了：
$b \mapsto P(A|B = b)=L(b|A)$表示在事件A发生的条件下，参数B是b的可能性。并且似然函数乘以一个正的常数之后仍然是似然函数
$$L(B=b|A)=\alpha P(A|B=b),\alpha > 0$$

#### 例子

抛硬币实验，一般来说，已知抛出的硬币正面朝上和反面朝上的概率各为
$p_H=0.5$，因此若2次投币都是正面朝上的概率为：
$$P(HH|p_H=0.5)=0.5^2=0.25$$,其中$H$表示正面朝上。
<br />
在统计学中，当我们所关心的是在**已经知道一系列抛掷结果时**，关于硬币抛掷式正面朝上的可能性的信息。则此时的条件概率改编为：
$$P(p_H|HH)=L(p_H|HH)$$
在本例中在连续抛掷两次都是正面朝上的条件下 $p_H=0.5$的似然性为：
$$L(p_H=0.5|HH)=P(HH|p_H=0.5)=0.25$$**这并不表示当观测到两次正面朝上时** $p_H=0.5$
**的**
*概率*
**是0.25**。
<br />
若假设$p_H=0.6$，那么其似然值将会改变为:
$$L(p_H=0.6|HH)=P(HH|p_H=0.6)=0.36$$
这表明当如果参数
$p_H$设置为0.6的话，观测到联系两次正面朝上的概率要比
$p_H=0.5$时更大。

#### 总结

条件概率和似然函数之间的区别在于两者所考虑的角度不同。
<br />
例如
$P=(A|B)$，若关注的是变量
$A$则表示在
$B$下的概率，是条件概率；若关注的变量是
$B$则表示在
$A$下的似然性。
